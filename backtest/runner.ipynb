{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import datetime\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import concurrent.futures\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.optimize import least_squares, minimize\n",
    "from scipy import linalg\n",
    "import statistics as stats\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# matrix helpers\n",
    "def _yi(price_series):\n",
    "    return [np.log(p) for p in price_series]\n",
    "\n",
    "def _fi(tc, m, time_series):\n",
    "    return [np.power((tc - t), m) if str(np.power((tc - t), m)) != 'nan' else 0 for t in time_series]\n",
    "     \n",
    "def _gi(tc, m, w, time_series):\n",
    "    return [np.power((tc - t), m) * np.cos(w * np.log(tc - t)) if str(np.power((tc - t), m) * np.cos(w * np.log(tc - t))) != 'nan' else 0 for t in time_series]\n",
    "\n",
    "def _hi(tc, m, w, time_series):\n",
    "    return [np.power((tc - t), m) * np.sin(w * np.log(tc - t)) if str(np.power((tc - t), m) * np.sin(w * np.log(tc - t))) != 'nan' else 0 for t in time_series]\n",
    "\n",
    "def _fi_pow_2(tc, m, time_series):\n",
    "    return np.power(_fi(tc, m, time_series), 2)\n",
    "\n",
    "def _gi_pow_2(tc, m, w, time_series):\n",
    "    return np.power(_gi(tc, m, w, time_series), 2)\n",
    "\n",
    "def _hi_pow_2(tc, m, w, time_series):\n",
    "    return np.power(_hi(tc, m, w, time_series), 2)\n",
    "\n",
    "def _figi(tc, m, w, time_series):\n",
    "    return np.multiply(_fi(tc, m, time_series), _gi(tc, m, w, time_series))\n",
    "\n",
    "def _fihi(tc, m, w, time_series):\n",
    "    return np.multiply(_fi(tc, m, time_series), _hi(tc, m, w, time_series))\n",
    "\n",
    "def _gihi(tc, m, w, time_series):\n",
    "    return np.multiply(_gi(tc, m, w, time_series), _hi(tc, m, w, time_series))\n",
    "\n",
    "def _yifi(tc, m, time_series, price_series):\n",
    "    return np.multiply(_yi(price_series), _fi(tc, m, time_series))\n",
    "\n",
    "def _yigi(tc, m, w, time_series, price_series):\n",
    "    return np.multiply(_yi(price_series), _gi(tc, m, w, time_series))\n",
    "\n",
    "def _yihi(tc, m, w, time_series, price_series):\n",
    "    return np.multiply(_yi(price_series), _hi(tc, m, w, time_series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revised version of the LPPL without φ\n",
    "# found on page 11 as equation (13)\n",
    "def lppl(t, tc, m, w, a, b, c1, c2):\n",
    "    return a + np.power(tc - t, m) * (b + ((c1 * np.cos(w * np.log(tc - t))) + (c2 * np.sin(w * np.log(tc - t)))))\n",
    "\n",
    "# finds the least square difference\n",
    "def func_restricted(x, *args):\n",
    "    \n",
    "    tc = x[0]\n",
    "    m  = x[1]\n",
    "    w  = x[2]\n",
    "    \n",
    "    data_series = args[0]\n",
    "       \n",
    "    lin_vals = matrix_equation(tc, m, w, data_series)\n",
    "\n",
    "    a  = lin_vals[0] \n",
    "    b  = lin_vals[1]\n",
    "    c1 = lin_vals[2] \n",
    "    c2 = lin_vals[3]\n",
    "\n",
    "    delta = [lppl(t, tc, m, w, a, b, c1, c2) for t in data_series[0]]\n",
    "    delta = np.subtract(delta, data_series[1])\n",
    "    delta = np.power(delta, 2)\n",
    "    return np.sum(delta)\n",
    "\n",
    "# solve the matrix equation\n",
    "def matrix_equation(tc, m, w, data_series):\n",
    "    time_series = data_series[0]\n",
    "    price_series = data_series[1]\n",
    "    N  = len(price_series)\n",
    "    \n",
    "    #--------------------------------\n",
    "    fi = sum(_fi(tc, m, time_series))\n",
    "    gi = sum(_gi(tc, m, w, time_series))\n",
    "    hi = sum(_hi(tc, m, w, time_series))\n",
    "\n",
    "    #--------------------------------\n",
    "    fi_pow_2 = sum(_fi_pow_2(tc, m, time_series))\n",
    "    gi_pow_2 = sum(_gi_pow_2(tc, m, w, time_series))\n",
    "    hi_pow_2= sum(_hi_pow_2(tc, m, w, time_series))\n",
    "\n",
    "    #--------------------------------\n",
    "    figi = sum(_figi(tc, m, w, time_series))\n",
    "    fihi = sum(_fihi(tc, m, w, time_series))\n",
    "    gihi = sum(_gihi(tc, m, w, time_series))\n",
    "\n",
    "    #--------------------------------\n",
    "    yi = sum(_yi(price_series))\n",
    "    yifi = sum(_yifi(tc, m, time_series, price_series))\n",
    "    yigi = sum(_yigi(tc, m, w, time_series, price_series))\n",
    "    yihi = sum(_yihi(tc, m, w, time_series, price_series))\n",
    "    \n",
    "    #--------------------------------\n",
    "    matrix_1 = np.matrix([\n",
    "        [N,  fi,       gi,       hi      ],\n",
    "        [fi, fi_pow_2, figi,     fihi    ],\n",
    "        [gi, figi,     gi_pow_2, gihi    ],\n",
    "        [hi, fihi,     gihi,     hi_pow_2]\n",
    "    ])\n",
    "    \n",
    "    matrix_2 = np.matrix([\n",
    "        [yi],\n",
    "        [yifi],\n",
    "        [yigi],\n",
    "        [yihi]\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        product = linalg.solve(matrix_1, matrix_2)\n",
    "        return [i[0] for i in product]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "upperbound = 126 # ~6 months (in trading days)\n",
    "lowerbound = 21 # ~1 month (in trading days)\n",
    "interval = 5\n",
    "\"\"\"       \n",
    "def compute_ds_lppls_confidence(args):\n",
    "    \n",
    "    df, symbol, upperbound, lowerbound, interval = args\n",
    "    \n",
    "    df2 = pd.DataFrame(df)\n",
    "    \n",
    "    ds_lppls = []\n",
    "    \n",
    "    number_of_fitting_windows = int((upperbound - lowerbound)/interval)\n",
    "    \n",
    "    for i in range(number_of_fitting_windows):\n",
    "\n",
    "        tLen = upperbound-(i*interval)\n",
    "        tradings_days_data = df.tail(tLen)\n",
    "        time = np.linspace(0, tLen-1, tLen)\n",
    "        price = np.array([tradings_days_data[i] for i in range(len(tradings_days_data))])\n",
    "        data_series = np.array([time, price])\n",
    "\n",
    "        MAX_SEARCHES = 5\n",
    "        SEARCH_COUNT = 0\n",
    "        \n",
    "        # set limits for non-linear params\n",
    "        bounds = [\n",
    "            (tLen-(tLen*0.2), tLen+(tLen*0.2)),    # Critical Time + or - .2\n",
    "            (0.1, 0.9),                            # m : 0.1 ≤ m ≤ 0.9\n",
    "            (6, 13),                               # ω : 6 ≤ ω ≤ 13     \n",
    "        ]\n",
    "\n",
    "        # find bubbles\n",
    "        while SEARCH_COUNT < MAX_SEARCHES:\n",
    "\n",
    "            # randomly choose vals for non-linear params \n",
    "            non_lin_vals = [random.uniform(a[0], a[1]) for a in bounds]\n",
    "\n",
    "            tc = non_lin_vals[0]\n",
    "            m  = non_lin_vals[1] \n",
    "            w  = non_lin_vals[2]\n",
    "\n",
    "            # params to pass to scipy.optimize\n",
    "            seed = np.array([tc, m, w])\n",
    "\n",
    "            # scipy optimize minimize\n",
    "            try:\n",
    "                # Nelder-Mead\n",
    "                cofs = minimize(\n",
    "                    args=(data_series, bounds), \n",
    "                    fun=func_restricted, \n",
    "                    method='Nelder-Mead', \n",
    "                    options={\n",
    "                        'adaptive': True\n",
    "                    },\n",
    "                    x0=seed\n",
    "                )\n",
    "                \n",
    "                if cofs.success:\n",
    "#                     print('minimize ran succsessfully in {} search(es)'.format(SEARCH_COUNT+1))\n",
    "                    # determine if it falls in range:\n",
    "\n",
    "                    tc = cofs.x[0]\n",
    "                    m =  cofs.x[1]\n",
    "                    w =  cofs.x[2]\n",
    "                    \n",
    "                    # calculate the linear vals again...\n",
    "                    lin_vals = matrix_equation(tc, m, w, data_series)\n",
    "\n",
    "                    a  = lin_vals[0] \n",
    "                    b  = lin_vals[1]\n",
    "                    c1 = lin_vals[2] \n",
    "                    c2 = lin_vals[3]\n",
    "                    \n",
    "                    # filtering conditions \n",
    "                    tc_in_range   = tLen-(tLen*0.05) < tc < tLen+(tLen*0.1)\n",
    "                    m_in_range    = 0.01 < m < 1.2\n",
    "                    w_in_range    = 2 < w < 25\n",
    "                    n_oscillation = ((w/2)*np.log(abs((tc - (i*5))/(tLen)))) > 2.5\n",
    "                    # for bubble end flag\n",
    "                    damping_bef   = (m*abs(b))/(w*abs(c1+c2)) > 0.8 \n",
    "                    # for bubble early warning \n",
    "                    damping_bew   = (m*abs(b))/(w*abs(c1+c2)) > 0.0 \n",
    "\n",
    "                    if (tc_in_range and m_in_range and w_in_range and n_oscillation and damping_bef):\n",
    "                        ds_lppls_confidence_bef = True\n",
    "                    else: \n",
    "                        ds_lppls_confidence_bef = False\n",
    "                        \n",
    "                    if (tc_in_range and m_in_range and w_in_range and n_oscillation and damping_bew):\n",
    "                        ds_lppls_confidence_bew = True\n",
    "                    else: \n",
    "                        ds_lppls_confidence_bew = False   \n",
    "\n",
    "                    ds_lppls.append({symbol: {\n",
    "                        'ds_lppls_confidence_bef': ds_lppls_confidence_bef,\n",
    "                        'ds_lppls_confidence_bew': ds_lppls_confidence_bew,\n",
    "                        'cof': cofs.x,\n",
    "                    }})\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    SEARCH_COUNT = SEARCH_COUNT + 1\n",
    "#                     print('minimize failed to find a solution, trying again')\n",
    "                    \n",
    "            except Exception as e:\n",
    "#                 print('minimize failed: {}'.format(e))\n",
    "                SEARCH_COUNT = SEARCH_COUNT + 1\n",
    "                \n",
    "        if SEARCH_COUNT >= MAX_SEARCHES:\n",
    "            # no solution found in 5 tries, so just add this and move one\n",
    "#             print('minimize failed in allotted attempts (5)')\n",
    "            ds_lppls.append({symbol: {\n",
    "                'ds_lppls_confidence_bef': False,\n",
    "                'ds_lppls_confidence_bew': False,\n",
    "                'cof': None,\n",
    "                'max_searches_exceeded': True\n",
    "            }})\n",
    "    \n",
    "    # calculate the actual ds lppls confidence value for end flag and early warning\n",
    "    true_count_bef = 0\n",
    "    true_count_bew = 0\n",
    "    total_count = len(ds_lppls)\n",
    "    for i in ds_lppls:\n",
    "        if i[symbol]['ds_lppls_confidence_bef'] == True:\n",
    "            true_count_bef = true_count_bef + 1\n",
    "        if i[symbol]['ds_lppls_confidence_bew'] == True:\n",
    "            true_count_bew = true_count_bew + 1   \n",
    "            \n",
    "    ds_lppls_confidence_bef_val = true_count_bef/total_count\n",
    "    ds_lppls_confidence_bew_val = true_count_bew/total_count\n",
    "    \n",
    "    # find the sign of the median of cumulative returns since the time t1\n",
    "    df2['ret']  = (df2[symbol]/df2[symbol].shift(1))-1\n",
    "    df2['cum_ret'] = df2['ret'].cumsum()\n",
    "#     print(df2.head())\n",
    "    median = stats.median(df2['cum_ret'].tolist())\n",
    "#     print('median: {}'.format(median))\n",
    "    median_sign = 1 if median > 0 else -1\n",
    "#     print('median_sign: {}'.format(median_sign))\n",
    "    \n",
    "    return {\n",
    "        'val_bef': ds_lppls_confidence_bef_val * median_sign,\n",
    "        'val_bew': ds_lppls_confidence_bew_val * median_sign,\n",
    "        'date': df.tail(1).index.tolist()[0],\n",
    "        'price': df.tail(1).tolist()[0],\n",
    "        'symbol': symbol,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix is singular.\n",
      "array must not contain infs or NaNs\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "array must not contain infs or NaNs\n",
      "Matrix is singular.\n",
      "array must not contain infs or NaNs\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "array must not contain infs or NaNs\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "array must not contain infs or NaNs\n",
      "array must not contain infs or NaNs\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "array must not contain infs or NaNs\n",
      "Matrix is singular.\n",
      "Matrix is singular.\n",
      "array must not contain infs or NaNs\n",
      "Matrix is singular.\n",
      "400.9632177352905\n",
      "[{'val_bef': -0.0, 'val_bew': -0.0, 'date': '2019-10-24', 'price': 161.89, 'symbol': 'MMM'}, {'val_bef': 0.0, 'val_bew': 0.0, 'date': '2019-10-24', 'price': 81.36, 'symbol': 'ABT'}, {'val_bef': -0.0, 'val_bew': -0.047619047619047616, 'date': '2019-10-24', 'price': 76.8, 'symbol': 'ABBV'}]\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "master_csv = 'https://boulderinvestmenttech.s3.amazonaws.com/iex_etl/data/agg/master.csv'\n",
    "data = pd.read_csv(master_csv, index_col=\"date\")\n",
    "data.fillna(method='ffill')\n",
    "\n",
    "master_data_len = len(data)\n",
    "window_len = 126\n",
    "# ground_to_cover = 1 # days\n",
    "workers = 8 # 12 locked-up your macbook bro\n",
    "\n",
    "# list of symbols from iex_etl/config.py \n",
    "# SP500 = ['MMM', 'ABT', 'ABBV', 'ABMD', 'ACN', 'ATVI', 'ADBE', 'AMD', 'AAP', 'AES', 'AMG', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALXN', 'ALGN', 'ALLE', 'AGN', 'ADS', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'AIV', 'AAPL', 'AMAT', 'APTV', 'ADM', 'ARNC', 'ANET', 'AJG', 'AIZ', 'ATO', 'T', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BHGE', 'BLL', 'BAC', 'BK', 'BAX', 'BBT', 'BDX', 'BRK.B', 'BBY', 'BIIB', 'BLK', 'HRB', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BF.B', 'CHRW', 'COG', 'CDNS', 'CPB', 'COF', 'CPRI', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CBS', 'CDW', 'CE', 'CELG', 'CNC', 'CNP', 'CTL', 'CERN', 'CF', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'XEC', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'CXO', 'COP', 'ED', 'STZ', 'COO', 'CPRT', 'GLW', 'CTVA', 'COST', 'COTY', 'CCI', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'FANG', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DOV', 'DOW', 'DTE', 'DUK', 'DRE', 'DD', 'DXC', 'ETFC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'EMR', 'ETR', 'EOG', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'EVRG', 'ES', 'RE', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FB', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FE', 'FRC', 'FISV', 'FLT', 'FLIR', 'FLS', 'FMC', 'F', 'FTNT', 'FTV', 'FBHS', 'FOXA', 'FOX', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GL', 'GPN', 'GS', 'GWW', 'HAL', 'HBI', 'HOG', 'HIG', 'HAS', 'HCA', 'HCP', 'HP', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HFC', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HPQ', 'HUM', 'HBAN', 'HII', 'IEX', 'IDXX', 'INFO', 'ITW', 'ILMN', 'IR', 'INTC', 'ICE', 'IBM', 'INCY', 'IP', 'IPG', 'IFF', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JKHY', 'JEC', 'JBHT', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KSS', 'KHC', 'KR', 'LB', 'LHX', 'LH', 'LRCX', 'LW', 'LEG', 'LDOS', 'LEN', 'LLY', 'LNC', 'LIN', 'LKQ', 'LMT', 'L', 'LOW', 'LYB', 'MTB', 'MAC', 'M', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MKC', 'MXIM', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MHK', 'TAP', 'MDLZ', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'MYL', 'NDAQ', 'NOV', 'NKTR', 'NTAP', 'NFLX', 'NWL', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NBL', 'JWN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'ORLY', 'OXY', 'OMC', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PH', 'PAYX', 'PYPL', 'PNR', 'PBCT', 'PEP', 'PKI', 'PRGO', 'PFE', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTN', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'CRM', 'SBAC', 'SLB', 'STX', 'SEE', 'SRE', 'SHW', 'SPG', 'SWKS', 'SLG', 'SNA', 'SO', 'LUV', 'SPGI', 'SWK', 'SBUX', 'STT', 'SYK', 'STI', 'SIVB', 'SYMC', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TFX', 'TXN', 'TXT', 'TMO', 'TIF', 'TWTR', 'TJX', 'TSCO', 'TDG', 'TRV', 'TRIP', 'TSN', 'UDR', 'ULTA', 'USB', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WAB', 'WMT', 'WBA', 'DIS', 'WM', 'WAT', 'WEC', 'WCG', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XYL', 'YUM', 'ZBH', 'ZION', 'ZTS']\n",
    "\n",
    "SP500 = ['MMM', 'ABT', 'ABBV']\n",
    "start = time.time()\n",
    "\n",
    "pool = multiprocessing.Pool(processes=workers)\n",
    "# compute the ds_lppls_confidence\n",
    "# `data[symbol].iloc[-window_len:]` returns the tail of the data df of length `window_len`\n",
    "result = pool.map(compute_ds_lppls_confidence, [(data[symbol].iloc[-window_len:], symbol, window_len, 21, 5) for symbol in SP500])\n",
    "pool.close()\n",
    "end = time.time()\n",
    "duration_of_fit = end - start\n",
    "print(duration_of_fit) \n",
    "print(result)\n",
    "print('------------')\n",
    "\n",
    "df_to_csv = pd.DataFrame(result)\n",
    "df_to_csv.to_csv('~/indicators.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_bef</th>\n",
       "      <th>val_bew</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>161.89</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>81.36</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>76.80</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_bef   val_bew        date   price symbol\n",
       "0     -0.0 -0.000000  2019-10-24  161.89    MMM\n",
       "1      0.0  0.000000  2019-10-24   81.36    ABT\n",
       "2     -0.0 -0.047619  2019-10-24   76.80   ABBV"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the confidence indicators\n",
    "fig, ax1 = plt.subplots(figsize=(25,12))\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('time (days)')\n",
    "ax1.set_ylabel('price', color=color)\n",
    "ax1.plot(t, price, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('val_bef', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(t, val_bef, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax3 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:green'\n",
    "ax3.set_ylabel('val_bew', color=color)  # we already handled the x-label with ax1\n",
    "ax3.plot(t, val_bew, color=color)\n",
    "ax3.tick_params(axis='y', labelcolor=color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
